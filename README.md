# Tasks
Naming convertion:

1_Individual_Task_Taskname
<BR> 
2_DML_DDL	
<BR> 
3_Adhoc	
<BR> 
4_GD_TOPICS	
<BR> 
5_Excel	<BR>
  1) certificate <BR>
	2) Interactive dashboard
 <BR>
6_WindowsFunction	

<BR> Deadine: June _10 2023
<BR> Task 1 : 
Video  https://drive.google.com/file/d/1aZN062NYOdSHpc05kz9Bghfl5NJbL_Mv/view?usp=share_link
<BR> Look into this video and create the tables as mentioned (understand the logic for table creation and insertion records)
also look into be the below sheet (Common Tasks section) for constraints and column names
<BR> sheet: https://docs.google.com/spreadsheets/d/1_Or1OiGHEMZp4i865tcqnFhQr5K3wH8uB2LwRgLQFz4/edit#gid=1171415896
<BR> Once completed post your github link in the updated_first_assesment section of the above sheet

<BR> Note:
1. Create a repository Sql_taskl in GitHub to upload the codes <BR> 
2. Copy and paste the code in notepad++ and upload in GitHub in the name 1_SQL_table_creation as a file name inside the repository Sql_task1<BR> 
3. Perform the DML and DDL INTERVIEW operations discussed upon these tables you created  and upload the queries as 2_DML_DDL_Tasks inside the Sql_task1
  use this as a reference link: https://github.com/Analyticsavenue/SQL-Basics/blob/main/4_DDL_DML_Interview%20questions.sql <BR> 
4. Once completed post your GitHub link in the updated_first_assesment section of the tasks sheet
   https://docs.google.com/spreadsheets/d/1_Or1OiGHEMZp4i865tcqnFhQr5K3wH8uB2LwRgLQFz4/edit#gid=1171415896 <BR> 

<BR> <B> recent update - 9th July 2023 <b/>
<BR>
5. do the below naming conversions and create new repository and store all your tasks in the respective bins <BR>
1_Individual_Task_Aptitude	 <BR> 
2_DML_DDL	<BR> 
3_Adhoc	<BR> 
4_GD_TOPICS	v<BR> 
5_Excel	1) certificate 
	2) Interactive dashboard <BR> 
6_WindowsFunction <BR> 
<BR> 
6. Make the gd videos ready and upload the video in google drive and paste URL inside the gd topics repository <BR> 
<BR> 
<BR> 
7. Windows Function <BR> 
   a) Update the changes in the employee table as added in the SQL basics repository - 4_WindowsFunctions_Duplicates.sql <BR> 
   b)Generate the consecutive numbers for each record locationswise <BR> 
   c) From the employee tables derive a new table called employee_updated with no duplicates <BR> 
   d) FRom the employee write a select query to get all the duplicate phone numbers <BR> 
   e) Implement a logic to show the difference between row_number and row_id <BR> 
   f) implement the different common table expressions to implement the below case statements <BR> 
---Case 1: Arrange the employees in increasing order of their salary <BR> 
---Case 2: Arrange the employees based on the increasing order of their salary location wise <BR> 
---Case 3: Pick the employee with the second-highest salary in each location <BR> 
---Case 4: Pick the employee with least salary in each location <BR> 
<BR> 
8. Store the ad-hoc tasks in a repository 3_Adhoc <BR> 
After importing the sales data set run the below code link: **https://github.com/Analyticsavenue/sample_code/blob/main/Sales_analysis_main.sql**
<BR>
Then perform the below tasks <BR> 
create a new table called Sales_order_info as a derived table from the above then it should  have																									
Product_ID																									
,Category																									
,Sub_Category																									
,Product_Name																									
,Sales																									
,Quantity																									
, per_quantity_price																									
, sales_type																									
,Discount																									
,Profit																									
, Loss	
<BR> 
and follow the below pattern
<BR> 																																												
1)product id should be  in this format	 <BR> 																								
ex FUR-BO-10001798 to 10001798	<BR> 																								
2) per_quantity_price should be  output of Sales / Quantity of each customer records	<BR> 																								
3) sales_type should be 3 categories			<BR> 																						
if sales are higher than 1000 then 'Super'		<BR> 																							
if sales are higher than 400 but lesser than 1000  then 'Average'	<BR> 																								
if sales are lesser than 400 then 'low'					<BR> 																				
4)Loss will be 1 if profit is negative		<BR> 																																																										
------Use single select statements to execute the below	<BR> 																																														
5) Count of distinct order_ids in the sales_purchase_data_updated table			<BR> 																						
6) Count of Unique product names in Sales_order_info					<BR> 																				
7) Count of distinct Segments in the sales_purchase_data_updated table					<BR> 																				
8) Recent order date in  sales_purchase_data_updated table		<BR> 																							
9)Old order date in sales_purchase_data_updated table		<BR> 																							
10) Customer info of all the columns for the maximum order date				<BR> 																					
11) No .of Unique Customers from Texas and New york					<BR> 																				
o/p No_of_cust_texas |  No_of_cust_New_york					<BR> 																				
   




   
   
